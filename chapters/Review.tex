\section{Review of useful concepts and Introduction}
\subsection{Multivariate Gaussian}
%$\sigma =$ covariance matrix, $\mu$ = mean\\
$f(x) = \frac{1}{2\pi \sqrt{|\Sigma|}} e^{- \frac{1}{2} (x-\mu)^T \Sigma^{-1} (x-\mu)}$

Suppose we have a Gaussian random vector $X_V \sim N(\mu_V, \Sigma_{VV})$.\\
Suppose we take two disjoint subsets of V: $A={i_1,...,i_k}$ and $B={j_1,...,j_m}$.\\
Then, the conditional distribution: \\
$P(X_A|X_B=x_B)=N(\mu_{A|B}, \Sigma_{A|B})$ is Gaussian:\\
$\mu_{A|B}=\mu_A+\Sigma_{AB}\Sigma^{-1}_{BB}(x_B-\mu_B)$\\
$\Sigma_{A|B}=\Sigma_{AA}-\Sigma_{AB}\Sigma^{-1}_{BB}\Sigma_{BA}$

\section{Bayesian Linear Regression}
\textbf{Prior:} $\rvw\sim\mathcal{N}(\mathbf{0},\Lambda^{-1})$\\
\textbf{Posterior:} $p(\rvw;\mathbf{X},\mathbf{y}) = \mathcal{N}(\rvw; \bar\mu, \bar\Sigma)$ where\\
$\bar\mu = (\mathbf{X}^T\mathbf{X} +\sigma^2\bm{\Lambda})^{-1}\mathbf{X}^T\mathbf{y}$\\
$\bar\Sigma = \sigma^2(\mathbf{X}^T\mathbf{X} +\sigma^2\bm{\Lambda})^{-1}$\\
\textbf{Pred.:}
\mbox{$y^* = {\vx^*}^T\rvw + \epsilon\sim \mathcal{N}({\vx^*}^T\bar\mu, \underbrace{{\vx^*}^T\bar\Sigma{\vx^*}}_\text{\color{purple}epistemic}+\underbrace{\sigma^2}_\text{\color{purple}aleatoric})$}
\textbf{\color{gray}Pred:}
$p(y^*|\rvx^*,\mX,\rvy) = \int p(y^*|\rvx^*,\rvw)p(\rvw|\mX,\rvy) d\rvw$

\section{Kalman Filters}
\textbf{Transition model}:
\mbox{$P(\rvx_{t+1}|\rvx_t)=\mathcal{N}(\rvx_{t+1};F\rvx_t, \Sigma_x)$}\\
\textbf{Sensor model}:
$P(\rvy_{t}|\rvx_t)=\mathcal{N}(\rvy_{t};H\rvx_t, \Sigma_y)$\\
\textbf{Conditioning:} $P(\rvx_t|\rvy_{1\ldots t}) = \mathcal{N}(\rvx_t;\mu_t, \Sigma_t)$\\
\textbf{Prediction:} $P(\rvx_{t+1}|\rvy_{1\ldots t}) = \mathcal{N}(\rvx_{t+1};F\mu_t, \Sigma_t + \Sigma_x)$\\
\textbf{Kalman gain}:
$K_{t+1}=$\\$(F\Sigma_t F^T+\Sigma_x)H^T(H(F\Sigma_t F^T+\Sigma_x)H^T+ \Sigma_y)^{-1}$\\
\textbf{Kalman update}:\\
$\mu_{t+1}=F\mu_t+K_{t+1}(\rvy_{t+1}-HF\mu_t)$\\
$\Sigma_{t+1}=(I-K_{t+1}H)(F\Sigma_tF^T + \Sigma_x)$\\
% asdf